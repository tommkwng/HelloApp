import os
os.environ["HOME"] = os.getcwd()  # è§£å†³streamlitæƒé™é—®é¢˜ï¼Œç¡®ä¿Streamlitèƒ½åœ¨å½“å‰ç›®å½•ä¸‹åˆ›å»ºé…ç½®æ–‡ä»¶

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM
import torch
import base64

# --------------------
# 0. Page config & sidebar
# --------------------
st.set_page_config(page_title='Weibo Sentiment Analysis & Auto Report', page_icon='ğŸ’¡', layout='wide')
st.sidebar.image('https://huggingface.co/front/assets/huggingface_logo-noborder.svg', width=120)
st.sidebar.markdown('''
**Weibo Sentiment Analysis & Auto Report System**  
- Automatic sentiment classification
- Sentiment distribution visualization
- Auto-generated analysis report
- Downloadable results
''')

# --------------------
# 1. Load sentiment analysis model (huggingfaceäº‘ç«¯æ¨¡å‹)
# --------------------
@st.cache_resource
def load_sentiment_model():
    # è¿™é‡Œå¡«å†™ä½ åœ¨huggingfaceä¸Šæ¨¡å‹çš„åå­—
    model_dir = 'Erica12345612/weibo-sentiment-bert'
    # è‡ªåŠ¨ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
    model = AutoModelForSequenceClassification.from_pretrained(model_dir)
    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    # åˆ›å»ºæƒ…æ„Ÿåˆ†æpipelineï¼Œè‡ªåŠ¨é€‰æ‹©GPUæˆ–CPU
    pipe = pipeline('text-classification', model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)
    return pipe

sentiment_pipe = load_sentiment_model()

# --------------------
# 2. Load English report generation model (gpt2, huggingfaceäº‘ç«¯æ¨¡å‹)
# --------------------
@st.cache_resource
def load_report_model():
    # ç›´æ¥ä»huggingfaceäº‘ç«¯åŠ è½½gpt2æ¨¡å‹
    model_dir = 'gpt2'
    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    model = AutoModelForCausalLM.from_pretrained(model_dir)
    return tokenizer, model

gen_tokenizer, gen_model = load_report_model()

def generate_summary_keyword(statistics):
    prompt = (
        f"Summarize the overall user sentiment for Weibo in one short English sentence, based on these results: {statistics}"
    )
    input_ids = gen_tokenizer(prompt, return_tensors='pt').input_ids
    output = gen_model.generate(
        input_ids,
        max_new_tokens=20,
        pad_token_id=gen_tokenizer.eos_token_id,
        no_repeat_ngram_size=3
    )
    keyword = gen_tokenizer.decode(output[0], skip_special_tokens=True).strip()
    return keyword

def generate_report(statistics):
    keyword = generate_summary_keyword(statistics)
    stat_dict = {}
    for item in statistics.split(','):
        if ':' in item:
            k, v = item.split(':')
            stat_dict[k.strip()] = v.strip()
    if stat_dict:
        main_sentiment = max(stat_dict, key=lambda k: int(stat_dict[k]))
        main_count = stat_dict[main_sentiment]
    else:
        main_sentiment = 'N/A'
        main_count = '0'
    summary = f"The overall sentiment among Weibo users is {keyword}."
    report = f'''
Sentiment Analysis Report

Summary:
{summary}
The sentiment analysis of recent Weibo posts shows the following distribution: {statistics}.
Among all posts, the most common sentiment is "{main_sentiment}" with {main_count} occurrences.

Possible Reasons:
A high proportion of 'none' sentiment may indicate that users are posting more neutral or informational content, or that the sentiment detection model needs further tuning for the Weibo context. This distribution may also be influenced by recent events, product updates, or public opinion trends. Positive sentiments such as 'like' and 'happiness' indicate user satisfaction, while 'none' or negative sentiments may reflect dissatisfaction or lack of engagement.

Business Implications:
Weibo can use these insights to optimize content recommendation and user engagement strategies. The company should leverage positive feedback to reinforce strengths, while paying close attention to negative or neutral sentiments to identify areas for improvement. Understanding the root causes behind these sentiments can help guide business strategy and improve platform experience.

Suggestions for Improvement:
1. Regularly monitor sentiment trends to detect changes in user attitudes.
2. Engage with users who express negative or neutral sentiments to gather feedback.
3. Promote positive experiences and address common pain points.
4. Use sentiment insights to inform product and service enhancements.

This report is generated automatically by the Weibo Sentiment Analysis & Auto Report System. It can be used for product optimization, user operations, and strategic decision support.
'''
    return report.strip()

# --------------------
# 3. Download sample CSV
# --------------------
def get_table_download_link(df):
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()  # some strings
    href = f'<a href="data:file/csv;base64,{b64}" download="sample_weibo.csv">Download sample CSV</a>'
    return href

sample_df = pd.DataFrame({
    'text': [
        'ä»Šå¤©å¿ƒæƒ…ç‰¹åˆ«å¥½ï¼Œé˜³å…‰çœŸç¾ï¼',
        'è¿™ä¸ªæœåŠ¡å¤ªå·®äº†ï¼ŒçœŸè®©äººç”Ÿæ°”ã€‚',
        'æœ‰ç‚¹å¤±è½ï¼Œäº‹æƒ…æ²¡æŒ‰é¢„æœŸå‘å±•ã€‚',
        'æ”¶åˆ°æƒŠå–œç¤¼ç‰©ï¼Œå¥½å¼€å¿ƒï¼',
        'æ²¡ä»€ä¹ˆç‰¹åˆ«çš„æ„Ÿè§‰ï¼Œå°±æ˜¯æ™®é€šä¸€å¤©ã€‚',
        'æœ€è¿‘å‹åŠ›å¾ˆå¤§ï¼Œæœ‰ç‚¹å®³æ€•æœªæ¥ã€‚',
        'æˆ‘å¾ˆå–œæ¬¢è¿™æ¬¾äº§å“ï¼Œæ¨èï¼',
        'çœ‹åˆ°è¿™äº›æ¶ˆæ¯çœŸçš„å¾ˆæ¶å¿ƒã€‚',
        'å®¢æœæ€åº¦éå¸¸å¥½ï¼Œç‚¹èµã€‚',
        'å¿«é€’å¤ªæ…¢äº†ï¼Œå¤±æœ›ã€‚',
        'ç»å¯¹çˆ±ä¸Šäº†è¿™ä¸ªåŠŸèƒ½ï¼',
        'å’Œé¢„æœŸä¸ä¸€æ ·ï¼Œæœ‰ç‚¹å¤±æœ›ã€‚',
        'æ–°ç‰ˆæœ¬æ›´æ–°å¾ˆæ£’ï¼Œä½“éªŒæå‡äº†ã€‚',
        'ä¸ºä»€ä¹ˆæ€»æ˜¯å¡é¡¿ï¼Ÿ',
        'å”®åæ”¯æŒå¾ˆåŠæ—¶ï¼Œæ»¡æ„ã€‚',
        'æ„Ÿè§‰è¢«å¿½è§†äº†ï¼Œæœ‰ç‚¹éš¾è¿‡ã€‚',
        'è¿™æ˜¯æˆ‘ç”¨è¿‡æœ€æ£’çš„åº”ç”¨ã€‚',
        'å†ä¹Ÿä¸ä¼šä¹°è¿™å®¶ä¸œè¥¿äº†ã€‚',
        'æ“ä½œå¾ˆæ–¹ä¾¿ï¼Œçœå¿ƒçœåŠ›ã€‚',
        'å¤ªç³Ÿç³•äº†ï¼Œä½“éªŒæå·®ã€‚'
    ]
})

# --------------------
# 4. Streamlit UI
# --------------------
st.markdown('<h1 style="color:#FF6F00;font-size:2.5em;">Weibo Sentiment Analysis & Auto Report</h1>', unsafe_allow_html=True)
st.markdown('<hr style="border:1px solid #FF6F00;">', unsafe_allow_html=True)
st.write('**Upload or input Weibo texts. The system will analyze sentiment distribution, generate visualizations, and auto-generate a brief report.**')

st.markdown(get_table_download_link(sample_df), unsafe_allow_html=True)
st.info("Please upload a CSV file with a column named 'text'. You can download a sample above.")

texts = []
input_mode = st.radio('Select input method:', ['Batch upload CSV', 'Manual input'])

if input_mode == 'Batch upload CSV':
    uploaded_file = st.file_uploader('Upload a CSV file with a column named "text"', type=['csv'])
    st.write("uploaded_file:", uploaded_file)
    if uploaded_file is not None:
        st.success(f"File {uploaded_file.name} uploaded successfully!")
        st.write("File name:", uploaded_file.name)
        st.write("File type:", uploaded_file.type)
        st.write("File size:", uploaded_file.size)
        try:
            df = pd.read_csv(uploaded_file)
            st.write(df.head())
            st.write("Columns:", df.columns.tolist())
        except Exception as e:
            st.error(f"Error reading file: {e}")
        if 'text' not in df.columns:
            st.error('CSV file must contain a column named "text"!')
            st.stop()
        texts = df['text'].astype(str).tolist()
        st.write("Texts loaded:", texts[:3])
else:
    for i in range(5):
        text = st.text_input(f'Input Weibo text #{i+1} (optional)')
        if text:
            texts.append(text)

if texts:
    st.markdown('---')
    st.subheader('1. ğŸ¯ Sentiment Analysis Results')
    with st.spinner('Analyzing sentiment...'):
        results = sentiment_pipe(texts)
    label_map = {
        '0': 'like', '1': 'disgust', '2': 'happiness', '3': 'sadness',
        '4': 'anger', '5': 'surprise', '6': 'fear', '7': 'none',
        'like': 'like', 'disgust': 'disgust', 'happiness': 'happiness',
        'sadness': 'sadness', 'anger': 'anger', 'surprise': 'surprise',
        'fear': 'fear', 'none': 'none',
        'LABEL_0': 'like', 'LABEL_1': 'disgust', 'LABEL_2': 'happiness', 'LABEL_3': 'sadness',
        'LABEL_4': 'anger', 'LABEL_5': 'surprise', 'LABEL_6': 'fear', 'LABEL_7': 'none'
    }
    pred_labels = [label_map.get(str(r['label']), r['label']) for r in results]
    df_result = pd.DataFrame({'Text': texts, 'Sentiment': pred_labels, 'Confidence': [round(r['score'], 3) for r in results]})
    st.dataframe(df_result.style.background_gradient(cmap='Oranges'))

    st.markdown('---')
    st.subheader('2. ğŸ“Š Sentiment Distribution Visualization')
    stat = df_result['Sentiment'].value_counts().sort_index()
    fig, ax = plt.subplots(1, 2, figsize=(12, 4))
    colors = plt.cm.Paired.colors
    stat.plot.pie(autopct='%1.1f%%', ax=ax[0], title='Sentiment Distribution (Pie)', colors=colors)
    stat.plot.bar(ax=ax[1], title='Sentiment Distribution (Bar)', color='#FF6F00')
    ax[0].set_ylabel('')
    st.pyplot(fig)

    st.markdown('---')
    st.subheader('3. ğŸ“ Auto-generated Analysis Report')
    stat_str = ', '.join([f'{k}: {v}' for k, v in stat.items()])
    with st.spinner('Generating report...'):
        report = generate_report(stat_str)
    st.success(report)

    st.markdown('---')
    st.subheader('4. â¬‡ï¸ Download Results')
    csv = df_result.to_csv(index=False).encode('utf-8')
    st.download_button('Download Results CSV', csv, 'sentiment_results.csv', 'text/csv')
else:
    st.info('Please upload a CSV file or manually input Weibo texts.')